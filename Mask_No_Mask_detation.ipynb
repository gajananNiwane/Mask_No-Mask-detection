{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1149465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e33d928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "without_mask=np.load('With_out_mask1.npy')\n",
    "with_mask=np.load('With_mask1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ef94be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 50, 50, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54672090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 50, 50, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd708a8c",
   "metadata": {},
   "source": [
    "Now we can see that data is loaded with the shape 200, 50, 50, 3.\n",
    "\n",
    "Here 200 is the number of images we have collected\n",
    "50, 50 is the size of each image\n",
    "3 is the color channel (red, green, blue)\n",
    "We can reshape the data to make it 2D :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e9c73f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert four dimention data into two dimentional\n",
    "with_mask=with_mask.reshape(200,50*50*3)\n",
    "without_mask=without_mask.reshape(200,50*50*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edf03de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 7500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3883154c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 7500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6d50a",
   "metadata": {},
   "source": [
    "we will concatenate the data into a single array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4afff89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate the two datasets \n",
    "X=np.r_[with_mask,without_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48cf340a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 7500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e6c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label datasets by using 0 and 1.0\n",
    "labels=np.zeros(X.shape[0]) # we are converting all 400 labels as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "684fcd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[200:]=1.0 # then last 200 convet in 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04ed7719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we apply as name\n",
    "names={0:'Mask',1:'No Mask'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use svm algorithum to classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90376198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a2c7aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "372ce88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,labels,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cedf58f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 7500)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26a19f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have lot of columns they slow the classification machine larning algorithum that why we use PCA method to reduce dimention of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7534bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensionality Reuction\n",
    "from sklearn.decomposition import PCA \n",
    "pca=PCA(n_components=3)\n",
    "x_train=pca.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6454a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "739bee06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3682.37605071,  3853.51362465,  1936.58635487])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "093e4ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigen value / Eigen vectore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "80c14ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm=SVC()\n",
    "svm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17fa561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also reduce the dimention of test datasets \n",
    "x_test=pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c959c",
   "metadata": {},
   "source": [
    "we will concatenate the data into a single array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "05ce73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c40446e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9916666666666667"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we chake the accuracy of over model\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4789b74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52,  1],\n",
       "       [ 0, 60]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perfomace \n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7245b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99        57\n",
      "         1.0       0.98      1.00      0.99        63\n",
      "\n",
      "    accuracy                           0.99       120\n",
      "   macro avg       0.99      0.99      0.99       120\n",
      "weighted avg       0.99      0.99      0.99       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886c9beb",
   "metadata": {},
   "source": [
    "we can test our faces with or without mask and check whether this algorithm is able to identity you that you are wearing a mask or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2290e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(\"C:\\\\Users\\\\Ankush Niwane\\\\Downloads\\\\machine_larning program\\\\haar-cascade-files-master\\\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "font=cv2.FONT_HERSEY_COMPLEX\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    if ret:\n",
    "        \n",
    "        faces = face_cascade.detectMultiScale(img)\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            face=img[y:y+h,x:x+w,:]\n",
    "            face=cv2.resize(face,(50,50))\n",
    "            face=face.reshape(1,-1)\n",
    "            face=pca.transform(face)\n",
    "            pred=svm.predict(face)[0]\n",
    "            n=names[int(pred)]\n",
    "            cv2.putText(img,n,(x,y),font,1,(255,0,0),2)\n",
    "            print(n)\n",
    "            \n",
    "            \n",
    "        cv2.imshow('img',img)\n",
    "        if cv2.waitKey(2)==27 :\n",
    "            break\n",
    "        \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "machine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
